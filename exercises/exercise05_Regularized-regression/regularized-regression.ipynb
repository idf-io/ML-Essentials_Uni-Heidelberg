{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2f2006c5-13fa-483c-8c1a-92f2777f4ce5",
   "metadata": {},
   "source": [
    "# Exercise 5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "870d82fc-6b92-44b7-a21d-afd3ee3fd3ce",
   "metadata": {},
   "source": [
    "## 1 Bias and variance of ridge regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ed1cfd4-4fd7-474f-af11-ff70c8b8bf32",
   "metadata": {},
   "source": [
    "* True model: y = Xβ* + ε\n",
    "\n",
    "* Zero-mean Gaussian noise: ε ~ N(0, σ^2)\n",
    "\n",
    "* Centered features assumption: (1/N) * Σ Xi = 0\n",
    "\n",
    "* Regularization parameter: τ ≥ 0\n",
    "\n",
    "Prove that the expectation E[βτ] and covariance Cov[βτ] of the regularized solution βτ are given by:\n",
    "        \n",
    "        E[βτ] = (Sτ)⁻¹S β∗\n",
    "        Cov[βτ] = (Sτ)⁻¹S (Sτ)⁻¹σ^2\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f86a08-aa3d-46ec-a98c-00c98f25ba34",
   "metadata": {},
   "source": [
    "**Step 1: Use the SVD of X:**\n",
    "\n",
    "X = UΣVᵀ (where U and V are orthogonal matrices, Uᵀ = U⁻¹)\n",
    "\n",
    "**Step 2: Compute S and Sτ:**\n",
    "\n",
    "S = XᵀX = (UΣVᵀ)ᵀ(UΣVᵀ) = VΣᵀΣVᵀ\n",
    "\n",
    "Sτ = XᵀX + τI = VΣᵀΣVᵀ + τI\n",
    "\n",
    "**Step 3: Compute E[βτ]:**\n",
    "\n",
    "βτ = argminβ (y - Xβ)ᵀ(y - Xβ) + τβᵀβ\n",
    "\n",
    "= (yᵀ - βᵀXᵀ)(y - Xβ) + τβᵀβ\n",
    "\n",
    "= yᵀy - yᵀXβ - βᵀXᵀy + βᵀXᵀXβ + τβᵀβ\n",
    "\n",
    "To compute E[βτ], we can take the derivative of the function with respect to β and set it to zero:\n",
    "\n",
    "0 = -Xᵀy + XᵀXβ + τβ\n",
    "\n",
    "Xᵀy = XᵀXβ + τβ = β(XᵀX + τ)\n",
    "\n",
    "β = (XᵀX + τI)⁻¹Xᵀy\n",
    "\n",
    "E[βτ] = E[(XᵀX + τI)⁻¹Xᵀy] = (XᵀX + τI)⁻¹XᵀE[y]\n",
    "\n",
    "Since we assumed that the noise ε is zero-mean, E[y] = Xβ*\n",
    "\n",
    "E[βτ] = (XᵀX + τI)⁻¹XᵀXβ*\n",
    "\n",
    "E[βτ] = (S + τI)⁻¹XᵀXβ*\n",
    "\n",
    "Finally, since S = XᵀX and Sτ = XᵀX + τI, we have:\n",
    "\n",
    "E[βτ] = (Sτ)⁻¹Sβ*\n",
    "\n",
    "**Step 4: Compute Cov[βτ]:**\n",
    "\n",
    "Cov[βτ] = Cov[(XᵀX + τI)⁻¹Xᵀy]\n",
    "\n",
    "= (XᵀX + τI)⁻¹XᵀCov[y](XᵀX + τI)⁻¹\n",
    "\n",
    "Since we assumed that the noise ε is zero-mean, Cov[y] = σ^2I:\n",
    "\n",
    "Cov[βτ] = (XᵀX + τI)⁻¹Xᵀ(σ^2I)(XᵀX + τI)⁻¹\n",
    "\n",
    "= (XᵀX + τI)⁻¹Xᵀσ^2I(XᵀX + τI)⁻¹\n",
    "\n",
    "= σ^2(XᵀX + τI)⁻¹Xᵀ(XᵀX + τI)⁻¹\n",
    "\n",
    "Finally, since S = XᵀX and Sτ = XᵀX + τI, we have:\n",
    "\n",
    "Cov[βτ] = σ^2(Sτ)⁻¹Xᵀ(Sτ)⁻¹"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff77a1db-23a1-4a89-ad7c-0ef841331064",
   "metadata": {},
   "source": [
    "## 2 LDA-Derivation from Least Squares Error"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8b50a52-1a0c-4f06-9c8c-2cbacc8ea56d",
   "metadata": {},
   "source": [
    "## 3 Automatic feature selection for LDA as regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef24c2f1-accd-4130-9676-15313041e6b2",
   "metadata": {},
   "source": [
    "## 3.1 Implement Orthagonal Matching Pursuit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9fe2b4-07ec-4ba6-b4eb-3fdb6f80387d",
   "metadata": {},
   "source": [
    "## 3.2 Classification with sparse LDA"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
